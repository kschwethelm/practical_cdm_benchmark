model: "meta-llama/Llama-3.3-70B-Instruct"

download_dir: /srv/llm-weights
served-model-name: "default"

host: "localhost"
port: 8000

tensor-parallel-size: 1
quantization: bitsandbytes
max-model-len: 16384
enable-prefix-caching: true