model: "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"
download_dir: /srv/llm-weights
served-model-name: "default"
host: "localhost"
port: 8000

enable-prefix-caching: true
quantization: bitsandbytes

max-model-len: 16384
tensor-parallel-size: 1
